qwen3vl_control_node:
  ros__parameters:
    # 图像源配置
    # 图像来源选择: "ros2" 或 "rtsp"
    #  - "ros2": 从 ROS2 话题获取图像（需要订阅 image_topic）
    #  - "rtsp": 从 RTSP 视频流获取图像（需要设置 rtsp_url）
    image_source: "ros2"

    # 输入图像话题（RealSense RGBD，仅在 image_source="ros2" 时使用）
    image_topic: "/camera/camera/color/image_raw"

    # RTSP 视频流地址（仅在 image_source="rtsp" 时使用）
    rtsp_url: "rtsp://192.168.168.168:8554/test"

    # 控制信号话题：
    #  - control_topic: std_msgs/msg/String，取值为"操场"时，开始场景解析（使用 caption_prompt，只缓存，不发送）
    #  - control_topic_2: std_msgs/msg/Int8，取值为1或2时：
    #      * 值为 1：使用 caption_prompt 进行解析
    #      * 值为 2：使用 text_cap_prompt 进行解析
    #      * 如果有缓存结果，直接发送缓存结果（不进行解析）
    #      * 如果没有缓存结果，开始场景解析并在解析完成后发送结果
    control_topic: "/nav/arrival"             # 控制信号话题 1 (String类型，触发词: "操场"，使用 caption_prompt 解析后缓存)
    control_topic_2: "/navigation/florence"   # 控制信号话题 2 (Int8类型，期望值: 1=caption, 2=text_cap，触发发送)

    # 模型相关配置
    # Qwen3-VL 模型路径（本地路径或 HuggingFace 模型 ID）
    # 例如: "Qwen/Qwen3-VL-2B-Instruct" 或 "/path/to/local/model"
    model_path: "/home/ubun/robot/Florence2Semantic/models/qwen3-vl-2B-Instruct"

    # 提示词模板配置
    # 根据 control_topic_2 的值选择不同的 prompt：
    #  - 值为 1 时使用 caption_prompt
    #  - 值为 2 时使用 text_cap_prompt
    caption_prompt: "要求：1) 使用纯文本，不要使用markdown格式、分隔符、换行符等特殊字符；2) 不要使用'照片'、'图片'、'视角'、'画面'、'这张'等词汇，直接描述场景本身；3) 用一段连贯的文字描述，不要分段；"
    text_cap_prompt: "只描述显示器上的文字内容。要求：1)使用纯文本，不要使用markdown格式、分隔符、换行符等特殊字符；2)用一段连贯的文字对内容进行辅助说明"

    # 结果发布话题
    result_topic: "/florence2/caption"

    # 文本生成相关参数
    max_new_tokens: 1024   # 最大生成 token 数
    temperature: 0.1       # 采样温度（0.0-1.0，值越大越随机）
    top_p: 0.5            # Nucleus sampling 参数（0.0-1.0）
    do_sample: true       # 是否使用采样生成（true=采样，false=贪婪解码）

    # 模型加载相关参数
    trust_remote_code: true  # 是否信任远程代码（HuggingFace 自定义模型代码）

    # 图像处理相关配置
    # 是否在语义生成前将图像旋转180度，如果使用ros2模式，则需要设置为true，如果使用rtsp模式，则需要设置为false。因为安装的realsense摄像头是倒置的，而狗自带的相机是正置的。
    flip: false

