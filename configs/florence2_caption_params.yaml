florence2_control_node:
  ros__parameters:
    # 图像源配置
    # 图像来源选择: "ros2" 或 "rtsp"
    #  - "ros2": 从 ROS2 话题获取图像（需要订阅 image_topic）
    #  - "rtsp": 从 RTSP 视频流获取图像（需要设置 rtsp_url）
    image_source: "ros2"

    # 输入图像话题（RealSense RGBD，仅在 image_source="ros2" 时使用）
    image_topic: "/camera/camera/color/image_raw"

    # RTSP 视频流地址（仅在 image_source="rtsp" 时使用）
    rtsp_url: "rtsp://192.168.168.168:8554/test"

    # 控制信号话题（支持两个话题，任一话题收到触发信号即可触发）：
    #  - control_topic: std_msgs/msg/String，取值为"操场"时，开始场景解析
    #  - control_topic_2: std_msgs/msg/Int8，取值为1时，开始场景解析
    control_topic: "/nav/arrival"             # 控制信号话题 1 (String类型，触发词: "操场")
    control_topic_2: "/navigation/florence"  # 控制信号话题 2 (Int8类型，期望值: 1，可选，如果与话题1相同则忽略)

    # 发送准备接受结果的话题
    #  - 期望类型: std_msgs/msg/Bool
    #  - 取值为true时，表示准备接受结果
    ready_topic: "/speech/ready"

    # 模型相关配置
    # Florence2 本地模型路径（或 HuggingFace 模型 ID）
    model_path: "/home/ubun/robot/Florence2Semantic/models/florence"

    # 任务类型：
    #  - caption           : 简要描述
    #  - detailed_cap      : 详细描述
    #  - more_detailed_cap : 更详细描述
    task_type: "more_detailed_cap"

    # 结果发布话题
    result_topic: "/florence2/caption"

    # 是否在日志中输出详细时间统计（总时间、推理时间、FPS 等）
    show_timing: false

    # 文本生成相关参数
    max_new_tokens: 1024   # 最大生成 token 数
    num_beams: 3           # Beam search 的 beam 数
    do_sample: false       # 是否使用采样生成（true=采样，false=纯 beam search）

    # 是否信任远程代码（HuggingFace 自定义模型代码）
    trust_remote_code: true

    # 翻译相关配置
    # 是否将生成的英文描述翻译为中文
    translate_to_chinese: true

    # 翻译模型配置（二选一）：
    # 方式1: 使用 HuggingFace 模型 ID（会自动下载）
    translation_model: "Helsinki-NLP/opus-mt-en-zh"
    
    # 方式2: 使用本地模型路径（如果设置了此参数，将优先使用本地路径）
    # translation_model_path: "/path/to/local/translation/model"
    translation_model_path: "/home/ubun/robot/Florence2Semantic/models/opus-mt-en-ch"

    # 图像处理相关配置
    # 是否在语义生成前将图像旋转180度，如果使用ros2模式，则需要设置为true，如果使用rtsp模式，则需要设置为false。因为安装的realsense摄像头是倒置的，而狗自带的相机是正置的。
    flip: false

