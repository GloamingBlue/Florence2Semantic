#!/usr/bin/env python3
"""
Qwen3-VL å›¾åƒæè¿°ç”Ÿæˆè„šæœ¬ï¼ˆç²¾ç®€ç‰ˆï¼‰
ä½¿ç”¨ Qwen3-VL-2B-Instruct æ¨¡å‹ç”Ÿæˆå›¾åƒæè¿°ï¼ˆHuggingFace æ ¼å¼ï¼‰
ç²¾ç®€ç‰ˆï¼šç§»é™¤äº†æ€§èƒ½ç›‘æµ‹å’Œæ—¶é—´è®¡ç®—åŠŸèƒ½ï¼Œåªä¿ç•™æ ¸å¿ƒè¯­ä¹‰ç”ŸæˆåŠŸèƒ½
"""

import warnings
import sys
import argparse
import threading
import gc
from pathlib import Path
from unittest.mock import patch
from typing import Union, Optional

warnings.filterwarnings("ignore")

try:
    import torch
    from PIL import Image
    import numpy as np
    from transformers import Qwen3VLForConditionalGeneration, AutoProcessor
    from transformers.dynamic_module_utils import get_imports
except ImportError as e:
    print(f"âŒ ç¼ºå°‘å¿…è¦çš„ä¾èµ–åŒ…: {e}")
    print("è¯·å®‰è£…: pip install torch transformers pillow numpy")
    sys.exit(1)

# å¯¼å…¥ ROS2 ç›¸å…³åº“
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image as ROSImage
from std_msgs.msg import Int8, String, Bool

# å¯¼å…¥ cv_bridge å’Œ OpenCVï¼Œç”¨äºå›¾åƒè½¬æ¢
from cv_bridge import CvBridge
import cv2


class Qwen3VLCaption:
    """Qwen3-VL å›¾åƒæè¿°ç”Ÿæˆå™¨"""

    # ä»»åŠ¡ç±»å‹å¯¹åº”çš„æç¤ºè¯æ¨¡æ¿
    PROMPT_TEMPLATES = {
        "caption": "ç›´æ¥æè¿°åœºæ™¯å†…å®¹ï¼ŒåŒ…æ‹¬åœºæ™¯ä¸­çš„ç‰©ä½“åŠå…¶ä½ç½®å…³ç³»ã€‚è¦æ±‚ï¼š1) ä½¿ç”¨çº¯æ–‡æœ¬ï¼Œä¸è¦ä½¿ç”¨markdownæ ¼å¼ã€åˆ†éš”ç¬¦ã€æ¢è¡Œç¬¦ç­‰ç‰¹æ®Šå­—ç¬¦ï¼›2) ä¸è¦ä½¿ç”¨'ç…§ç‰‡'ã€'å›¾ç‰‡'ã€'ç”»é¢'ã€'è¿™å¼ 'ç­‰è¯æ±‡ï¼Œç›´æ¥æè¿°åœºæ™¯æœ¬èº«ï¼›3) ç”¨ä¸€æ®µè¿è´¯çš„æ–‡å­—æè¿°ï¼Œä¸è¦åˆ†æ®µï¼›4) æ¯ä¸ªç‰©ä½“æˆ–ç‰¹å¾åªæè¿°ä¸€æ¬¡ï¼Œä¸è¦é‡å¤æè¿°ç›¸åŒçš„å†…å®¹ï¼›5) é¿å…å¾ªç¯é‡å¤ï¼Œæè¿°è¦ç®€æ´å®Œæ•´",
        "detailed_cap": "ç›´æ¥è¯¦ç»†æè¿°åœºæ™¯å†…å®¹ï¼ŒåŒ…æ‹¬æ‰€æœ‰å¯è§çš„ç‰©ä½“ã€å®ƒä»¬çš„ä½ç½®ã€é¢œè‰²ã€çº¹ç†ã€åœºæ™¯ä¸Šä¸‹æ–‡å’Œå…‰ç…§æ¡ä»¶ã€‚è¦æ±‚ï¼š1) ä½¿ç”¨çº¯æ–‡æœ¬ï¼Œä¸è¦ä½¿ç”¨markdownæ ¼å¼ã€åˆ†éš”ç¬¦ã€æ¢è¡Œç¬¦ç­‰ç‰¹æ®Šå­—ç¬¦ï¼›2) ä¸è¦ä½¿ç”¨'ç…§ç‰‡'ã€'å›¾ç‰‡'ã€'ç”»é¢'ã€'è¿™å¼ 'ç­‰è¯æ±‡ï¼Œç›´æ¥æè¿°åœºæ™¯æœ¬èº«ï¼›3) ç”¨ä¸€æ®µè¿è´¯çš„æ–‡å­—æè¿°ï¼Œä¸è¦åˆ†æ®µï¼›4) æ¯ä¸ªç‰©ä½“æˆ–ç‰¹å¾åªæè¿°ä¸€æ¬¡ï¼Œä¸è¦é‡å¤æè¿°ç›¸åŒçš„å†…å®¹ï¼›5) é¿å…å¾ªç¯é‡å¤ï¼Œæè¿°è¦ç®€æ´å®Œæ•´ï¼›6) å¦‚æœå¤šä¸ªä½ç½®æœ‰ç›¸åŒç±»å‹çš„ç‰©ä½“ï¼Œå¯ä»¥ç»Ÿä¸€æè¿°ï¼Œä¸è¦é€ä¸ªé‡å¤",
        "more_detailed_cap": "ç›´æ¥éå¸¸è¯¦ç»†åœ°æè¿°åœºæ™¯å†…å®¹ï¼ŒåŒ…æ‹¬æ‰€æœ‰å¯è§çš„ç‰©ä½“ã€å®ƒä»¬çš„ä½ç½®ã€é¢œè‰²ã€çº¹ç†ã€åœºæ™¯ä¸Šä¸‹æ–‡ã€å…‰ç…§æ¡ä»¶å’Œå…¶ä»–ç›¸å…³ç»†èŠ‚ã€‚è¦æ±‚ï¼š1) ä½¿ç”¨çº¯æ–‡æœ¬ï¼Œä¸è¦ä½¿ç”¨markdownæ ¼å¼ã€åˆ†éš”ç¬¦ã€æ¢è¡Œç¬¦ç­‰ç‰¹æ®Šå­—ç¬¦ï¼›2) ä¸è¦ä½¿ç”¨'ç…§ç‰‡'ã€'å›¾ç‰‡'ã€'ç”»é¢'ã€'è¿™å¼ 'ç­‰è¯æ±‡ï¼Œç›´æ¥æè¿°åœºæ™¯æœ¬èº«ï¼›3) ç”¨ä¸€æ®µè¿è´¯çš„æ–‡å­—æè¿°ï¼Œä¸è¦åˆ†æ®µï¼›4) æ¯ä¸ªç‰©ä½“æˆ–ç‰¹å¾åªæè¿°ä¸€æ¬¡ï¼Œä¸è¦é‡å¤æè¿°ç›¸åŒçš„å†…å®¹ï¼›5) é¿å…å¾ªç¯é‡å¤ï¼Œæè¿°è¦ç®€æ´å®Œæ•´ï¼›6) å¦‚æœå¤šä¸ªä½ç½®æœ‰ç›¸åŒç±»å‹çš„ç‰©ä½“ï¼Œå¯ä»¥ç»Ÿä¸€æè¿°ï¼Œä¸è¦é€ä¸ªé‡å¤ï¼›7) ä¿æŒæè¿°çš„å¤šæ ·æ€§å’Œè¿è´¯æ€§ï¼Œé¿å…ä½¿ç”¨ç›¸åŒçš„å¥å¼é‡å¤æè¿°",
    }

    def __init__(
        self,
        model_path: str,
        task_type: str = "caption",
        trust_remote_code: bool = True,
        max_new_tokens: int = 1024,
        temperature: float = 0.7,
        top_p: float = 0.8,
        do_sample: bool = True,
    ):
        """
        åˆå§‹åŒ– Qwen3-VL æ¨¡å‹ï¼ˆHuggingFace æ ¼å¼ï¼‰

        Args:
            model_path: æ¨¡å‹è·¯å¾„ï¼ˆæœ¬åœ°è·¯å¾„æˆ– HuggingFace æ¨¡å‹ IDï¼Œå¦‚ "Qwen/Qwen3-VL-2B-Instruct"ï¼‰
            task_type: ä»»åŠ¡ç±»å‹ï¼Œå¯é€‰ "caption", "detailed_cap", "more_detailed_cap"
            trust_remote_code: æ˜¯å¦ä¿¡ä»»è¿œç¨‹ä»£ç 
            max_new_tokens: æœ€å¤§ç”Ÿæˆ token æ•°
            temperature: é‡‡æ ·æ¸©åº¦
            top_p: nucleus sampling å‚æ•°
            do_sample: æ˜¯å¦ä½¿ç”¨é‡‡æ ·ç”Ÿæˆ
        """
        if task_type not in self.PROMPT_TEMPLATES:
            raise ValueError(
                f"ä¸æ”¯æŒçš„ä»»åŠ¡ç±»å‹: {task_type}ã€‚"
                f"æ”¯æŒçš„ç±»å‹: {list(self.PROMPT_TEMPLATES.keys())}"
            )

        self.task_type = task_type
        self.prompt_template = self.PROMPT_TEMPLATES[task_type]
        self.max_new_tokens = max_new_tokens
        self.temperature = temperature
        self.top_p = top_p
        self.do_sample = do_sample

        # è‡ªåŠ¨é€‰æ‹©è®¾å¤‡
        self.device = "cuda:0" if torch.cuda.is_available() else "cpu"
        self.torch_dtype = (
            torch.float16 if torch.cuda.is_available() else torch.float32
        )

        print(f"ğŸ”„ æ­£åœ¨åŠ è½½æ¨¡å‹: {model_path}")
        print(f"ğŸ“± ä½¿ç”¨è®¾å¤‡: {self.device}")

        # ä¿®å¤ CPU ä¸Š flash_attn çš„é—®é¢˜
        def fixed_get_imports(filename):
            imports = get_imports(filename)
            if not torch.cuda.is_available() and "flash_attn" in imports:
                imports.remove("flash_attn")
            return imports

        # åŠ è½½æ¨¡å‹å’Œå¤„ç†å™¨
        with patch(
            "transformers.dynamic_module_utils.get_imports", fixed_get_imports
        ):
            self.model = Qwen3VLForConditionalGeneration.from_pretrained(
                model_path,
                torch_dtype=self.torch_dtype,
                device_map=self.device,
                trust_remote_code=trust_remote_code,
                attn_implementation="eager",  # å› ä¸ºaarchæ¶æ„ä¸Šæš‚æœªæ‰¾åˆ°é€‚é…gqaçš„torchç‰ˆæœ¬,å¦‚æœç”¨çš„æ˜¯x86æ¶æ„,å¯ä»¥æ³¨é‡Šæ‰è¿™è¡Œ
            )
            self.processor = AutoProcessor.from_pretrained(
                model_path,
                trust_remote_code=trust_remote_code,
            )

        print(f"âœ… Qwen3-VL æ¨¡å‹åŠ è½½å®Œæˆ")

    def generate_caption(
        self, 
        image: Union[str, Image.Image, np.ndarray]
    ) -> str:
        """
        ä¸ºå›¾åƒç”Ÿæˆæè¿°

        Args:
            image: å›¾åƒè¾“å…¥ï¼Œå¯ä»¥æ˜¯ï¼š
                  - str: å›¾åƒæ–‡ä»¶è·¯å¾„
                  - PIL.Image: PIL å›¾åƒå¯¹è±¡
                  - np.ndarray: numpy æ•°ç»„ï¼ˆRGB æ ¼å¼ï¼Œshape: [H, W, 3]ï¼‰

        Returns:
            å›¾åƒæè¿°æ–‡æœ¬
        """
        # è¯»å–å’Œè½¬æ¢å›¾åƒ
        if isinstance(image, str):
            # æ–‡ä»¶è·¯å¾„
            if not Path(image).exists():
                raise FileNotFoundError(f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image}")
            pil_image = Image.open(image).convert("RGB")
        elif isinstance(image, Image.Image):
            # PIL.Image
            pil_image = image.convert("RGB")
        elif isinstance(image, np.ndarray):
            # numpy æ•°ç»„
            if len(image.shape) != 3 or image.shape[2] != 3:
                raise ValueError(f"numpy æ•°ç»„å¿…é¡»æ˜¯ RGB æ ¼å¼ï¼Œshape: [H, W, 3]ï¼Œå½“å‰: {image.shape}")
            pil_image = Image.fromarray(image.astype(np.uint8))
        else:
            raise TypeError(f"ä¸æ”¯æŒçš„å›¾åƒç±»å‹: {type(image)}ï¼Œæ”¯æŒç±»å‹: str, PIL.Image, np.ndarray")

        # æ„å»ºæ¶ˆæ¯æ ¼å¼ï¼ˆæ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼‰
        prompt = self.prompt_template
        messages = [
            {
                "role": "user",
                "content": [
                    {
                        "type": "image",
                        "image": pil_image,  # ç›´æ¥ä¼ å…¥ PIL Image å¯¹è±¡
                    },
                    {"type": "text", "text": prompt},
                ],
            }
        ]

        # ä½¿ç”¨ apply_chat_template å¤„ç†æ¶ˆæ¯ï¼ˆæ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼‰
        print("ğŸ¤– æ­£åœ¨ç”Ÿæˆæè¿°...")
        inputs = self.processor.apply_chat_template(
            messages,
            tokenize=True,
            add_generation_prompt=True,
            return_dict=True,
            return_tensors="pt"
        )
        
        # å°†è¾“å…¥ç§»åŠ¨åˆ°è®¾å¤‡
        inputs = inputs.to(self.device)

        # ç”Ÿæˆæè¿°
        with torch.no_grad():
            generated_ids = self.model.generate(
                **inputs,
                max_new_tokens=self.max_new_tokens,
                do_sample=self.do_sample,
                temperature=self.temperature if self.do_sample else None,
                top_p=self.top_p if self.do_sample else None,
                repetition_penalty=1.3,  # æ·»åŠ é‡å¤æƒ©ç½šï¼Œå‡å°‘é‡å¤ç”Ÿæˆï¼ˆå€¼è¶Šå¤§ï¼Œæƒ©ç½šè¶Šå¼ºï¼‰
            )

        # æˆªå–æ–°ç”Ÿæˆçš„éƒ¨åˆ†ï¼ˆæ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼‰
        generated_ids_trimmed = [
            out_ids[len(in_ids):] 
            for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
        ]
        
        # è§£ç ç”Ÿæˆçš„æ–‡æœ¬
        output_text = self.processor.batch_decode(
            generated_ids_trimmed, 
            skip_special_tokens=True, 
            clean_up_tokenization_spaces=False
        )
        
        # æå–æè¿°æ–‡æœ¬
        final_caption = output_text[0].strip() if output_text else ""

        return final_caption
    
    def __del__(self):
        """æ¸…ç†èµ„æº"""
        if hasattr(self, "model"):
            del self.model
        if hasattr(self, "processor"):
            del self.processor
        if torch.cuda.is_available():
            torch.cuda.empty_cache()


# ROS2 è½»é‡çº§æ§åˆ¶èŠ‚ç‚¹ï¼ˆä¸åŠ è½½æ¨¡å‹ï¼‰
class Qwen3VLControlNode(Node):
    """
    è½»é‡çº§æ§åˆ¶èŠ‚ç‚¹ï¼Œè´Ÿè´£ï¼š
    - æŒç»­æ¥æ”¶å›¾åƒæµï¼Œä¿å­˜æœ€æ–°ä¸€å¸§
    - ç›‘å¬æ§åˆ¶ä¿¡å·
    - æ”¶åˆ°ä¿¡å· 1 æ—¶ï¼ŒæŒ‰éœ€åŠ è½½æ¨¡å‹ã€å¤„ç†å›¾åƒã€é‡Šæ”¾èµ„æº
    """
    
    def __init__(self):
        super().__init__('qwen3vl_control_node')
        
        # å‚æ•°å£°æ˜
        self.declare_parameter('image_source', 'ros2')  # å›¾åƒæ¥æº: "ros2" æˆ– "rtsp"
        self.declare_parameter('image_topic', '/camera/camera/color/image_raw')  # ROS2 å›¾åƒè¯é¢˜
        self.declare_parameter('rtsp_url', 'rtsp://192.168.168.168:8554/test')  # RTSP æµåœ°å€
        self.declare_parameter('control_topic', '/navigation/florence')  # æ§åˆ¶ä¿¡å·è¯é¢˜ 1
        self.declare_parameter('control_topic_2', '/nav/arrival')  # æ§åˆ¶ä¿¡å·è¯é¢˜ 2ï¼ˆå¯é€‰ï¼‰
        self.declare_parameter('ready_topic', '/speech/ready')  # å‡†å¤‡æ¥å—ç»“æœçš„è¯é¢˜
        self.declare_parameter('model_path', 'Qwen/Qwen3-VL-2B-Instruct')  # Qwen3-VL æ¨¡å‹è·¯å¾„ï¼ˆæœ¬åœ°è·¯å¾„æˆ– HuggingFace IDï¼‰
        self.declare_parameter('task_type', 'more_detailed_cap')
        self.declare_parameter('result_topic', '/florence2/caption')
        self.declare_parameter('max_new_tokens', 1024)
        self.declare_parameter('temperature', 0.7)  # é‡‡æ ·æ¸©åº¦
        self.declare_parameter('top_p', 0.8)  # nucleus sampling
        self.declare_parameter('do_sample', True)  # æ˜¯å¦ä½¿ç”¨é‡‡æ ·ç”Ÿæˆ
        self.declare_parameter('trust_remote_code', True)  # æ˜¯å¦ä¿¡ä»»è¿œç¨‹ä»£ç 
        self.declare_parameter('flip', False)  # æ˜¯å¦åœ¨è¯­ä¹‰ç”Ÿæˆå‰å°†å›¾åƒæ—‹è½¬180åº¦
        
        # è·å–å›¾åƒæºç±»å‹
        image_source = self.get_parameter('image_source').value
        
        # çº¿ç¨‹å®‰å…¨ï¼šæœ€æ–°å›¾åƒå­˜å‚¨
        self.latest_image_lock = threading.Lock()
        self.latest_image_msg = None  # ROS2 å›¾åƒæ¶ˆæ¯
        self.latest_rtsp_frame = None  # RTSP å¸§ï¼ˆnumpy arrayï¼‰
        
        # å¤„ç†çŠ¶æ€æ ‡å¿—ï¼ˆé¿å…é‡å¤å¤„ç†ï¼‰
        self.is_processing = False
        self.processing_lock = threading.Lock()
        
        # Ready çŠ¶æ€å’Œç»“æœç¼“å­˜
        self.ready_received = False
        self.cached_result = None
        self.ready_lock = threading.Lock()
        
        # RTSP ç›¸å…³
        self.rtsp_cap = None
        self.rtsp_thread = None
        self.rtsp_running = False
        
        # åˆå§‹åŒ– cv_bridgeï¼ˆç”¨äºå›¾åƒè½¬æ¢ï¼‰
        self.cv_bridge = CvBridge()
        
        # æ ¹æ®å›¾åƒæºç±»å‹åˆå§‹åŒ–
        if image_source == 'ros2':
            # ROS2 æ¨¡å¼ï¼šåˆ›å»ºå›¾åƒè®¢é˜…è€…
            image_topic = self.get_parameter('image_topic').value
            self.image_subscription = self.create_subscription(
                ROSImage,
                image_topic,
                self.image_callback,
                1  # QoS depth = 1ï¼Œåªä¿ç•™æœ€æ–°å›¾åƒ
            )
            self.get_logger().info(f'ğŸ“· å·²è®¢é˜…å›¾åƒè¯é¢˜: {image_topic}')
        elif image_source == 'rtsp':
            # RTSP æ¨¡å¼ï¼šå¯åŠ¨ RTSP æµè¯»å–çº¿ç¨‹
            rtsp_url = self.get_parameter('rtsp_url').value
            self._start_rtsp_stream(rtsp_url)
        else:
            raise ValueError(f'ä¸æ”¯æŒçš„å›¾åƒæºç±»å‹: {image_source}ï¼Œæ”¯æŒçš„ç±»å‹: "ros2", "rtsp"')
        
        # åˆ›å»ºæ§åˆ¶ä¿¡å·è®¢é˜…è€…ï¼ˆString ç±»å‹ï¼Œæ¥æ”¶ "æ“åœº" ç­‰è§¦å‘è¯ï¼‰
        # è®¢é˜…ç¬¬ä¸€ä¸ªæ§åˆ¶è¯é¢˜
        control_topic = self.get_parameter('control_topic').value
        self.control_subscription = self.create_subscription(
            String,
            control_topic,
            self.control_callback,
            10  # QoS depth = 10ï¼Œç¡®ä¿ä¿¡å·ä¸ä¸¢å¤±
        )
        self.get_logger().info(f'ğŸ® å·²è®¢é˜…æ§åˆ¶ä¿¡å·è¯é¢˜ 1: {control_topic} (Stringç±»å‹ï¼Œè§¦å‘è¯: "æ“åœº")')
        
        # è®¢é˜…ç¬¬äºŒä¸ªæ§åˆ¶è¯é¢˜ï¼ˆå¦‚æœé…ç½®äº†ä¸”ä¸è¯é¢˜1ä¸åŒï¼‰
        control_topic_2 = self.get_parameter('control_topic_2').value
        if control_topic_2 and control_topic_2 != control_topic:
            self.control_subscription_2 = self.create_subscription(
                Int8,
                control_topic_2,
                self.control_callback_2,
                10  # QoS depth = 10ï¼Œç¡®ä¿ä¿¡å·ä¸ä¸¢å¤±
            )
            self.get_logger().info(f'ğŸ® å·²è®¢é˜…æ§åˆ¶ä¿¡å·è¯é¢˜ 2: {control_topic_2} (Int8ç±»å‹ï¼ŒæœŸæœ›å€¼: 1)')
        else:
            self.control_subscription_2 = None
            if control_topic_2 == control_topic:
                self.get_logger().warn(f'âš ï¸  æ§åˆ¶è¯é¢˜ 2 ä¸è¯é¢˜ 1 ç›¸åŒï¼Œè·³è¿‡é‡å¤è®¢é˜…')
        
        # åˆ›å»º ready ä¿¡å·è®¢é˜…è€…
        ready_topic = self.get_parameter('ready_topic').value
        self.ready_subscription = self.create_subscription(
            Bool,
            ready_topic,
            self.ready_callback,
            10  # QoS depth = 10ï¼Œç¡®ä¿ä¿¡å·ä¸ä¸¢å¤±
        )
        self.get_logger().info(f'âœ… å·²è®¢é˜…å‡†å¤‡ä¿¡å·è¯é¢˜: {ready_topic} (Boolç±»å‹)')
        
        # åˆ›å»ºç»“æœå‘å¸ƒè€…
        result_topic = self.get_parameter('result_topic').value
        self.caption_publisher = self.create_publisher(
            String,
            result_topic,
            10
        )
        self.get_logger().info(f'ğŸ“¤ å·²åˆ›å»ºç»“æœå‘å¸ƒè¯é¢˜: {result_topic}')
        
        self.get_logger().info('âœ… Qwen3-VL Control Node åˆå§‹åŒ–å®Œæˆï¼ˆæ¨¡å‹æœªåŠ è½½ï¼‰')
        self.get_logger().info('â³ ç­‰å¾…æ§åˆ¶ä¿¡å·...')
    
    def image_callback(self, msg: ROSImage):
        """
        å›¾åƒè¯é¢˜å›è°ƒå‡½æ•° - æŒç»­æ¥æ”¶ï¼Œä¿å­˜æœ€æ–°ä¸€å¸§ï¼ˆROS2 æ¨¡å¼ï¼‰
        """
        with self.latest_image_lock:
            self.latest_image_msg = msg
    
    def _start_rtsp_stream(self, rtsp_url: str):
        """
        å¯åŠ¨ RTSP æµè¯»å–çº¿ç¨‹
        
        Args:
            rtsp_url: RTSP æµåœ°å€
        """
        self.get_logger().info(f'ğŸ”„ æ­£åœ¨è¿æ¥ RTSP æµ: {rtsp_url}')
        
        # åˆ›å»º VideoCapture å¯¹è±¡
        self.rtsp_cap = cv2.VideoCapture(rtsp_url)
        
        if not self.rtsp_cap.isOpened():
            self.get_logger().error(f'âŒ æ— æ³•æ‰“å¼€ RTSP æµ: {rtsp_url}')
            raise RuntimeError(f'æ— æ³•æ‰“å¼€ RTSP æµ: {rtsp_url}')
        
        # è®¾ç½®ç¼“å†²åŒºå¤§å°ï¼ˆå‡å°‘å»¶è¿Ÿï¼‰
        self.rtsp_cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
        
        self.rtsp_running = True
        
        # å¯åŠ¨è¯»å–çº¿ç¨‹
        self.rtsp_thread = threading.Thread(target=self._rtsp_read_loop, daemon=True)
        self.rtsp_thread.start()
        
        self.get_logger().info(f'âœ… RTSP æµè¯»å–çº¿ç¨‹å·²å¯åŠ¨: {rtsp_url}')
    
    def _rtsp_read_loop(self):
        """
        RTSP æµè¯»å–å¾ªç¯ï¼ˆåœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­è¿è¡Œï¼‰
        """
        while self.rtsp_running:
            ret, frame = self.rtsp_cap.read()
            if ret:
                # è½¬æ¢ä¸º RGB æ ¼å¼
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                with self.latest_image_lock:
                    self.latest_rtsp_frame = frame_rgb
            else:
                self.get_logger().warn('âš ï¸  RTSP æµè¯»å–å¤±è´¥ï¼Œå°è¯•é‡æ–°è¿æ¥...')
                # å°è¯•é‡æ–°è¿æ¥
                self.rtsp_cap.release()
                import time
                time.sleep(1)
                rtsp_url = self.get_parameter('rtsp_url').value
                self.rtsp_cap = cv2.VideoCapture(rtsp_url)
                if not self.rtsp_cap.isOpened():
                    self.get_logger().error(f'âŒ RTSP æµé‡è¿å¤±è´¥: {rtsp_url}')
                    break
                self.rtsp_cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
        
        # æ¸…ç†èµ„æº
        if self.rtsp_cap is not None:
            self.rtsp_cap.release()
            self.get_logger().info('ğŸ”„ RTSP æµå·²å…³é—­')
    
    def control_callback(self, msg: String):
        """
        æ§åˆ¶ä¿¡å·å›è°ƒå‡½æ•°
        msg.data: å½“æ¥æ”¶åˆ° "æ“åœº" æ—¶ï¼Œå¼€å§‹åŠ è½½æ¨¡å‹è¿›è¡Œè§£æ
        """
        trigger_word = msg.data.strip()
        
        if trigger_word != "æ“åœº":
            # ä¸æ˜¯è§¦å‘è¯ï¼Œè·³è¿‡å¤„ç†
            self.get_logger().debug(f'æ”¶åˆ°æ§åˆ¶ä¿¡å·: "{trigger_word}"ï¼Œä¸æ˜¯è§¦å‘è¯ "æ“åœº"ï¼Œè·³è¿‡å¤„ç†')
            return
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç¼“å­˜ç»“æœï¼Œå¦‚æœæœ‰å°±ä¸å†æ¬¡è§£æ
        with self.ready_lock:
            if self.cached_result is not None:
                self.get_logger().info('âš ï¸  å·²æœ‰ç¼“å­˜ç»“æœï¼Œè·³è¿‡æœ¬æ¬¡è§£æè¯·æ±‚ï¼ˆç­‰å¾… ready ä¿¡å·å‘é€ï¼‰')
                return
        
        # æ”¶åˆ° "æ“åœº"ï¼ŒæŒ‰éœ€åŠ è½½æ¨¡å‹å¹¶å¤„ç†
        self.get_logger().info('æ”¶åˆ°æ§åˆ¶ä¿¡å· "æ“åœº": å¼€å§‹å¤„ç†å›¾åƒ...')
        
        # æ£€æŸ¥æ˜¯å¦æ­£åœ¨å¤„ç†ï¼ˆé¿å…é‡å¤å¤„ç†ï¼‰
        with self.processing_lock:
            if self.is_processing:
                self.get_logger().warn('ä¸Šä¸€æ¬¡å¤„ç†å°šæœªå®Œæˆï¼Œè·³è¿‡æœ¬æ¬¡è¯·æ±‚')
                return
            self.is_processing = True
        
        try:
            # è·å–æœ€æ–°å›¾åƒï¼ˆæ ¹æ®å›¾åƒæºç±»å‹ï¼‰
            image_source = self.get_parameter('image_source').value
            
            if image_source == 'ros2':
                # ROS2 æ¨¡å¼ï¼šä»è¯é¢˜è·å–å›¾åƒ
                with self.latest_image_lock:
                    if self.latest_image_msg is None:
                        self.get_logger().warn('âš ï¸  å°šæœªæ”¶åˆ°å›¾åƒï¼Œæ— æ³•å¤„ç†')
                        return
                    image_msg = self.latest_image_msg
                self._process_with_model(image_msg)
            elif image_source == 'rtsp':
                # RTSP æ¨¡å¼ï¼šä» RTSP æµè·å–å›¾åƒ
                with self.latest_image_lock:
                    if self.latest_rtsp_frame is None:
                        self.get_logger().warn('âš ï¸  å°šæœªæ”¶åˆ° RTSP å¸§ï¼Œæ— æ³•å¤„ç†')
                        return
                    frame = self.latest_rtsp_frame.copy()
                self._process_with_rtsp_frame(frame)
            else:
                self.get_logger().error(f'âŒ ä¸æ”¯æŒçš„å›¾åƒæºç±»å‹: {image_source}')
                return
            
        except Exception as e:
            self.get_logger().error(f'âŒ å¤„ç†å›¾åƒæ—¶å‡ºé”™: {e}')
            import traceback
            self.get_logger().error(traceback.format_exc())
        finally:
            with self.processing_lock:
                self.is_processing = False
    
    def control_callback_2(self, msg: Int8):
        """
        æ§åˆ¶ä¿¡å·å›è°ƒå‡½æ•° 2ï¼ˆInt8 ç±»å‹ï¼‰
        msg.data: å½“æ¥æ”¶åˆ° 1 æ—¶ï¼Œå¼€å§‹åŠ è½½æ¨¡å‹è¿›è¡Œè§£æ
        """
        signal = msg.data
        
        if signal != 1:
            # ä¸æ˜¯æœŸæœ›å€¼ï¼Œè·³è¿‡å¤„ç†
            self.get_logger().debug(f'æ”¶åˆ°æ§åˆ¶ä¿¡å·: {signal}ï¼Œä¸æ˜¯æœŸæœ›å€¼ 1ï¼Œè·³è¿‡å¤„ç†')
            return
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç¼“å­˜ç»“æœï¼Œå¦‚æœæœ‰å°±ä¸å†æ¬¡è§£æ
        with self.ready_lock:
            if self.cached_result is not None:
                self.get_logger().info('âš ï¸  å·²æœ‰ç¼“å­˜ç»“æœï¼Œè·³è¿‡æœ¬æ¬¡è§£æè¯·æ±‚ï¼ˆç­‰å¾… ready ä¿¡å·å‘é€ï¼‰')
                return
        
        # æ”¶åˆ° 1ï¼ŒæŒ‰éœ€åŠ è½½æ¨¡å‹å¹¶å¤„ç†
        self.get_logger().info('æ”¶åˆ°æ§åˆ¶ä¿¡å· 1: å¼€å§‹å¤„ç†å›¾åƒ...')
        
        # æ£€æŸ¥æ˜¯å¦æ­£åœ¨å¤„ç†ï¼ˆé¿å…é‡å¤å¤„ç†ï¼‰
        with self.processing_lock:
            if self.is_processing:
                self.get_logger().warn('ä¸Šä¸€æ¬¡å¤„ç†å°šæœªå®Œæˆï¼Œè·³è¿‡æœ¬æ¬¡è¯·æ±‚')
                return
            self.is_processing = True
        
        try:
            # è·å–æœ€æ–°å›¾åƒï¼ˆæ ¹æ®å›¾åƒæºç±»å‹ï¼‰
            image_source = self.get_parameter('image_source').value
            
            if image_source == 'ros2':
                # ROS2 æ¨¡å¼ï¼šä»è¯é¢˜è·å–å›¾åƒ
                with self.latest_image_lock:
                    if self.latest_image_msg is None:
                        self.get_logger().warn('âš ï¸  å°šæœªæ”¶åˆ°å›¾åƒï¼Œæ— æ³•å¤„ç†')
                        return
                    image_msg = self.latest_image_msg
                self._process_with_model(image_msg)
            elif image_source == 'rtsp':
                # RTSP æ¨¡å¼ï¼šä» RTSP æµè·å–å›¾åƒ
                with self.latest_image_lock:
                    if self.latest_rtsp_frame is None:
                        self.get_logger().warn('âš ï¸  å°šæœªæ”¶åˆ° RTSP å¸§ï¼Œæ— æ³•å¤„ç†')
                        return
                    frame = self.latest_rtsp_frame.copy()
                self._process_with_rtsp_frame(frame)
            else:
                self.get_logger().error(f'âŒ ä¸æ”¯æŒçš„å›¾åƒæºç±»å‹: {image_source}')
                return
            
        except Exception as e:
            self.get_logger().error(f'âŒ å¤„ç†å›¾åƒæ—¶å‡ºé”™: {e}')
            import traceback
            self.get_logger().error(traceback.format_exc())
        finally:
            with self.processing_lock:
                self.is_processing = False
    
    def ready_callback(self, msg: Bool):
        """
        Ready ä¿¡å·å›è°ƒå‡½æ•°
        msg.data: true è¡¨ç¤ºå‡†å¤‡æ¥å—ç»“æœ
        """
        if msg.data:
            with self.ready_lock:
                if not self.ready_received:
                    self.ready_received = True
                    self.get_logger().info('âœ… æ”¶åˆ° ready ä¿¡å·: å‡†å¤‡æ¥å—ç»“æœ')
                    
                    # å¦‚æœæœ‰ç¼“å­˜çš„ç»“æœï¼Œç«‹å³å‘é€
                    if self.cached_result is not None:
                        self.get_logger().info('ğŸ“¤ å‘é€ç¼“å­˜çš„ç»“æœ...')
                        cached = self.cached_result
                        self.cached_result = None  # å…ˆæ¸…ç©ºç¼“å­˜ï¼Œé¿å…é‡å¤ä½¿ç”¨
                        self._publish_caption(cached)
                        print("\033[36m" + "â”€" * 80 + "\033[0m")
                    else:
                        # æ²¡æœ‰ç¼“å­˜ç»“æœï¼Œç­‰å¾…åç»­å¤„ç†ç»“æœ
                        self.get_logger().info('â³ å½“å‰æ²¡æœ‰ç¼“å­˜ç»“æœï¼Œç­‰å¾…åç»­å¤„ç†å®Œæˆåç›´æ¥å‘é€')
                else:
                    self.get_logger().debug('ready ä¿¡å·å·²æ¥æ”¶è¿‡ï¼Œå¿½ç•¥é‡å¤ä¿¡å·')
        else:
            self.get_logger().debug('æ”¶åˆ° ready=falseï¼Œå¿½ç•¥')
    
    def _process_with_model(self, image_msg: ROSImage):
        """
        æŒ‰éœ€åŠ è½½æ¨¡å‹ï¼Œå¤„ç† ROS2 å›¾åƒæ¶ˆæ¯ï¼Œç„¶åé‡Šæ”¾èµ„æº
        
        Args:
            image_msg: ROS2 Image æ¶ˆæ¯
        """
        # 1. è½¬æ¢å›¾åƒ
        self.get_logger().info('ğŸ”„ è½¬æ¢å›¾åƒ...')
        pil_image = self._ros_image_to_pil(image_msg)
        self._process_image(pil_image)
    
    def _process_with_rtsp_frame(self, frame: np.ndarray):
        """
        æŒ‰éœ€åŠ è½½æ¨¡å‹ï¼Œå¤„ç† RTSP å¸§ï¼Œç„¶åé‡Šæ”¾èµ„æº
        
        Args:
            frame: RTSP å¸§ï¼ˆRGB numpy arrayï¼‰
        """
        # 1. è½¬æ¢å›¾åƒ
        self.get_logger().info('ğŸ”„ è½¬æ¢å›¾åƒ...')
        pil_image = Image.fromarray(frame)
        self._process_image(pil_image)
    
    def _process_image(self, pil_image: Image.Image):
        """
        å¤„ç†å›¾åƒï¼ˆé€šç”¨æ–¹æ³•ï¼Œæ”¯æŒ ROS2 å’Œ RTSPï¼‰
        
        Args:
            pil_image: PIL Image å¯¹è±¡
        """
        caption_generator = None
        try:
            # 0. æ³¨æ„ï¼šä¸åœ¨è¿™é‡Œæ¸…ç©ºç¼“å­˜ï¼Œå› ä¸ºç¼“å­˜æ£€æŸ¥åœ¨ control_callback ä¸­å·²ç»å®Œæˆ
            # å¦‚æœè¿›å…¥è¿™é‡Œï¼Œè¯´æ˜æ²¡æœ‰ç¼“å­˜ç»“æœï¼Œå¯ä»¥å®‰å…¨åœ°è¿›è¡Œæ–°çš„å¤„ç†
            
            # 1.1 æ ¹æ® flip å‚æ•°å†³å®šæ˜¯å¦ç¿»è½¬å›¾åƒ
            flip = self.get_parameter('flip').value
            if flip:
                self.get_logger().info('ğŸ”„ æ­£åœ¨å°†å›¾åƒæ—‹è½¬180åº¦...')
                pil_image = pil_image.rotate(180)
            
            # 2. åŠ è½½æ¨¡å‹ï¼ˆæŒ‰éœ€åŠ è½½ï¼‰
            self.get_logger().info('ğŸ”„ æ­£åœ¨åŠ è½½ Qwen3-VL æ¨¡å‹ï¼ˆæŒ‰éœ€åŠ è½½ï¼‰...')
            caption_generator = Qwen3VLCaption(
                model_path=self.get_parameter('model_path').value,
                task_type=self.get_parameter('task_type').value,
                trust_remote_code=self.get_parameter('trust_remote_code').value,
                max_new_tokens=self.get_parameter('max_new_tokens').value,
                temperature=self.get_parameter('temperature').value,
                top_p=self.get_parameter('top_p').value,
                do_sample=self.get_parameter('do_sample').value,
            )
            
            # 3. ç”Ÿæˆæè¿°
            caption = caption_generator.generate_caption(pil_image)
            
            self.get_logger().info(f'âœ… ç”Ÿæˆæè¿°: {caption}')
            
            # 4. æ£€æŸ¥æ˜¯å¦å·²ç»æ¥æ”¶åˆ° ready ä¿¡å·
            with self.ready_lock:
                if self.ready_received:
                    # å·²ç»æ¥æ”¶åˆ° readyï¼Œç›´æ¥å‘é€ç»“æœ
                    self.get_logger().info('ğŸ“¤ ready ä¿¡å·å·²æ¥æ”¶ï¼Œç›´æ¥å‘é€ç»“æœ')
                    self._publish_caption(caption)
                    # å‘é€åæ¸…ç©ºç¼“å­˜ï¼ˆç¡®ä¿ä¸ä¼šé‡å¤ä½¿ç”¨ï¼‰
                    self.cached_result = None
                else:
                    # å°šæœªæ¥æ”¶åˆ° readyï¼Œç¼“å­˜ç»“æœ
                    self.get_logger().info('â³ å°šæœªæ¥æ”¶åˆ° ready ä¿¡å·ï¼Œç¼“å­˜ç»“æœï¼Œç­‰å¾… ready ä¿¡å·...')
                    self.cached_result = caption
            
        finally:
            # 5. é‡Šæ”¾æ¨¡å‹èµ„æº
            if caption_generator is not None:
                self.get_logger().info('ğŸ”„ æ­£åœ¨é‡Šæ”¾æ¨¡å‹èµ„æº...')
                self._cleanup_model(caption_generator)
                self.get_logger().info('âœ… æ¨¡å‹èµ„æºå·²é‡Šæ”¾')
                print("\033[36m" + "â”€" * 80 + "\033[0m")
    
    def _ros_image_to_pil(self, msg: ROSImage) -> Image.Image:
        """
        å°† ROS2 sensor_msgs/Image è½¬æ¢ä¸º PIL.Image
        
        Args:
            msg: ROS2 Image æ¶ˆæ¯
            
        Returns:
            PIL.Image å¯¹è±¡ï¼ˆRGB æ ¼å¼ï¼‰
        """
        try:
            # è½¬æ¢ä¸º OpenCV æ ¼å¼ (BGR)
            cv_image = self.cv_bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')
            # è½¬æ¢ä¸º RGB
            cv_image_rgb = cv2.cvtColor(cv_image, cv2.COLOR_BGR2RGB)
            # è½¬æ¢ä¸º PIL.Image
            pil_image = Image.fromarray(cv_image_rgb)
            return pil_image
        except Exception as e:
            self.get_logger().error(f'âŒ å›¾åƒè½¬æ¢å¤±è´¥: {e}')
            raise
    
    def _publish_caption(self, caption: str):
        """
        å‘å¸ƒæè¿°ç»“æœ
        
        Args:
            caption: å›¾åƒæè¿°æ–‡æœ¬
        """
        msg = String()
        msg.data = caption
        self.caption_publisher.publish(msg)
        self.get_logger().debug(f'ğŸ“¤ å·²å‘å¸ƒæè¿°ç»“æœ')
    
    def _cleanup_model(self, caption_generator: Qwen3VLCaption):
        """
        æ¸…ç†æ¨¡å‹èµ„æº

        Args:
            caption_generator: Qwen3VLCaption å®ä¾‹
        """
        try:
            # åˆ é™¤æ¨¡å‹å’Œå¤„ç†å™¨
            if hasattr(caption_generator, 'model'):
                del caption_generator.model
            if hasattr(caption_generator, 'processor'):
                del caption_generator.processor
            
            # æ¸…ç† GPU ç¼“å­˜
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                torch.cuda.synchronize()
            
            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            gc.collect()
            
        except Exception as e:
            self.get_logger().warn(f'âš ï¸  æ¸…ç†èµ„æºæ—¶å‡ºé”™: {e}')
    
    def destroy_node(self):
        """
        èŠ‚ç‚¹é”€æ¯æ—¶æ¸…ç†èµ„æº
        """
        # åœæ­¢ RTSP æµè¯»å–
        if self.rtsp_running:
            self.rtsp_running = False
            if self.rtsp_thread is not None:
                self.rtsp_thread.join(timeout=2.0)
            if self.rtsp_cap is not None:
                self.rtsp_cap.release()
        
        super().destroy_node()


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="ä½¿ç”¨ Qwen3-VL æ¨¡å‹ç”Ÿæˆå›¾åƒæè¿°ï¼ˆç²¾ç®€ç‰ˆï¼Œæ”¯æŒå‘½ä»¤è¡Œå’Œ ROS2 æ¨¡å¼ï¼‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # å‘½ä»¤è¡Œæ¨¡å¼
  python semantic_ros2.py --image path/to/image.jpg --model_path "Qwen/Qwen3-VL-2B-Instruct" --task_type detailed_cap

  # ROS2 æ¨¡å¼
  python semantic_ros2.py --ros2
        """,
    )

    parser.add_argument(
        "--ros2",
        action="store_true",
        help="ä»¥ ROS2 èŠ‚ç‚¹æ¨¡å¼è¿è¡Œï¼ˆéœ€è¦ ROS2 ç¯å¢ƒï¼‰",
    )
    parser.add_argument(
        "--image",
        type=str,
        help="è¾“å…¥å›¾åƒè·¯å¾„ï¼ˆå‘½ä»¤è¡Œæ¨¡å¼å¿…éœ€ï¼‰",
    )
    parser.add_argument(
        "--model_path",
        type=str,
        default="Qwen/Qwen3-VL-2B-Instruct",
        help="Qwen3-VL æ¨¡å‹è·¯å¾„ï¼ˆæœ¬åœ°è·¯å¾„æˆ– HuggingFace æ¨¡å‹ IDï¼Œå¦‚ Qwen/Qwen3-VL-2B-Instructï¼‰",
    )
    parser.add_argument(
        "--task_type",
        type=str,
        default="more_detailed_cap",
        choices=["caption", "detailed_cap", "more_detailed_cap"],
        help="ä»»åŠ¡ç±»å‹: caption (åŸºç¡€æè¿°), detailed_cap (è¯¦ç»†æè¿°), more_detailed_cap (æ›´è¯¦ç»†æè¿°)",
    )
    parser.add_argument(
        "--max_new_tokens",
        type=int,
        default=1024,
        help="æœ€å¤§ç”Ÿæˆ token æ•°ï¼ˆé»˜è®¤: 1024ï¼‰",
    )
    parser.add_argument(
        "--temperature",
        type=float,
        default=0.7,
        help="é‡‡æ ·æ¸©åº¦ï¼ˆé»˜è®¤: 0.7ï¼‰",
    )
    parser.add_argument(
        "--top_p",
        type=float,
        default=0.8,
        help="Nucleus sampling å‚æ•°ï¼ˆé»˜è®¤: 0.8ï¼‰",
    )
    parser.add_argument(
        "--do_sample",
        action="store_true",
        default=True,
        help="ä½¿ç”¨é‡‡æ ·ç”Ÿæˆï¼ˆé»˜è®¤: Trueï¼‰",
    )
    parser.add_argument(
        "--trust_remote_code",
        action="store_true",
        default=True,
        help="æ˜¯å¦ä¿¡ä»»è¿œç¨‹ä»£ç ï¼ˆé»˜è®¤: Trueï¼‰",
    )

    # ä½¿ç”¨ parse_known_args ä»¥å…¼å®¹ ROS2 çš„ --ros-args / --params-file ç­‰å‚æ•°
    args, _ = parser.parse_known_args()

    # ROS2 æ¨¡å¼
    if args.ros2:
        try:
            rclpy.init()
            node = Qwen3VLControlNode()
            rclpy.spin(node)
        except KeyboardInterrupt:
            print("\nâš ï¸  æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨å…³é—­èŠ‚ç‚¹...")
        except Exception as e:
            print(f"âŒ ROS2 èŠ‚ç‚¹è¿è¡Œå‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
        finally:
            if rclpy.ok():
                rclpy.shutdown()
        return

    # å‘½ä»¤è¡Œæ¨¡å¼
    if not args.image:
        parser.error("å‘½ä»¤è¡Œæ¨¡å¼éœ€è¦ --image å‚æ•°ï¼Œæˆ–ä½¿ç”¨ --ros2 è¿›å…¥ ROS2 æ¨¡å¼")

    try:
        # åˆ›å»ºæ¨¡å‹å®ä¾‹
        caption_generator = Qwen3VLCaption(
            model_path=args.model_path,
            task_type=args.task_type,
            trust_remote_code=args.trust_remote_code,
            max_new_tokens=args.max_new_tokens,
            temperature=args.temperature,
            top_p=args.top_p,
            do_sample=args.do_sample,
        )

        # ç”Ÿæˆæè¿°
        caption = caption_generator.generate_caption(args.image)

        # è¾“å‡ºç»“æœ
        print("\n" + "=" * 60)
        print("ğŸ“ å›¾åƒæè¿°:")
        print("=" * 60)
        print(caption)
        print("=" * 60)

    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()

